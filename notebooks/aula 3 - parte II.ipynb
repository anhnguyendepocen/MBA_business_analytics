{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![alt text](FGV_logo.png)\n",
    "\n",
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import de modulos pandas e numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# Math\n",
    "import math\n",
    "\n",
    "# import de modulos para graficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# imports para Machine Learning \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.cross_validation import train_test_split # modulo antigo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# para avaliacao\n",
    "from sklearn import metrics\n",
    "\n",
    "# dataset\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função logística\n",
    "\n",
    "A função logistica [Logistic Function](http://en.wikipedia.org/wiki/Logistic_function) recebe como argumento uma valor de $-\\infty$ a $+\\infty$, e retorna um valor no intervalo $(0,1)$\n",
    "\n",
    "$$ \\sigma (t)= \\frac{1}{1+e^{-t}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Função Logistica\n",
    "def logistic(t):\n",
    "    return 1.0 / (1 + math.exp((-1.0)*t) )\n",
    "\n",
    "# cria um grade de -6 a 6 ( 500 elementos, igualmente espaçados)\n",
    "x_grade = np.linspace(-6,6,500)\n",
    "\n",
    "# calcula os valores de y\n",
    "y = np.array([logistic(x) for x in x_grade])\n",
    "\n",
    "# usando exp do numpy que aceita um vetor como argumento\n",
    "y = 1/(1 + np.exp(-1.0 * x_grade))\n",
    "\n",
    "# plot\n",
    "plt.plot(x_grade,y)\n",
    "plt.title(' Funcao Logistica ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia é considerar a função logistica gerando uma probabilidade, a partir de um polinomio:\n",
    "\n",
    "\n",
    "$$ y = a_0 + a_1.x_{1} + a_2.x_{2} ... + a_m.x_{m}$$\n",
    "\n",
    "onde $a_0, a_1, ..., a_m$ são coeficientes a serem aprendidos, de forma que a equação abaixo:<br>\n",
    "\n",
    "\n",
    "$$ F(x)= \\frac{1}{1+e^{-(a_0 + a_1.x_{1} + a_2.x_{2} ... + a_m.x_{m})}}$$\n",
    "\n",
    "forneça a 'melhor' probabilidade de sucesso. \n",
    "\n",
    "Para tanto o algoritmo procura encontrar os melhores $a_0, a_1, ..., a_m$ que minimizam o erro. \n",
    "\n",
    "Na predição, o $x^{(i)}$ fornece um $F(x^{(i)})$. \n",
    "* Se $F(x^{(i)}) \\leq 0.5$, predição será a classe 0\n",
    "* Se $F(x^{(i)}) > 0.5$, predição será a classe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo prático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "url = 'http://statsmodels.sourceforge.net/stable/datasets/generated/fair.html'\n",
    "\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de observações: 6366\n",
    "Quantidade de features: 9\n",
    "Definições:\n",
    "\n",
    "    rate_marriage   : How rate marriage, 1 = very poor, 2 = poor, 3 = fair,\n",
    "                    4 = good, 5 = very good\n",
    "    age             : Age\n",
    "    yrs_married     : No. years married. Interval approximations. See\n",
    "                    original paper for detailed explanation.\n",
    "    children        : No. children\n",
    "    religious       : How relgious, 1 = not, 2 = mildly, 3 = fairly,\n",
    "                    4 = strongly\n",
    "    educ            : Level of education, 9 = grade school, 12 = high\n",
    "                    school, 14 = some college, 16 = college graduate,\n",
    "                    17 = some graduate school, 20 = advanced degree\n",
    "    occupation      : 1 = student, 2 = farming, agriculture; semi-skilled,\n",
    "                    or unskilled worker; 3 = white-colloar; 4 = teacher\n",
    "                    counselor social worker, nurse; artist, writers;\n",
    "                    technician, skilled worker, 5 = managerial,\n",
    "                    administrative, business, 6 = professional with\n",
    "                    advanced degree\n",
    "    occupation_husb : Husband's occupation. Same as occupation.\n",
    "    affairs         : measure of time spent in extramarital affairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carregando dataframe \n",
    "\n",
    "df = sm.datasets.fair.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define uma coluna, indicador binário que indica se a pessoa teve um caso extra-conjugal\n",
    "df['teve_affair'] = [ 1 if a else 0 for a in df.affairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Media por cada label\n",
    "df.groupby('teve_affair').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# desvio padrão por cada label\n",
    "df.groupby('teve_affair').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(data = df[df.affairs < 2], x = 'age', y = 'affairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.affairs.describe(percentiles=[0, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Countplot com idade\n",
    "sns.countplot(data=df, x='age', hue='teve_affair', palette='coolwarm')\n",
    "# sns.distplot(df[df.teve_affair == 0].age)\n",
    "# sns.distplot(df[df.teve_affair == 1].age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Countplot com anos de casamento\n",
    "sns.countplot('yrs_married',data=df,hue='teve_affair',palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Countplot com quantidade de filhos\n",
    "sns.countplot('children',data=df,hue='teve_affair',palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Countplot com nivel de educação\n",
    "sns.countplot('educ',data=df,hue='teve_affair',palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# considerando que a pessoa teve um caso extra-conjugal, \n",
    "# visualizacão da distribuição por boxplot\n",
    "sns.boxplot(data=df[df.affairs > 0], x='age', y = 'affairs')\n",
    "plt.ylim(0, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# considerando que a pessoa teve um caso extra-conjugal, \n",
    "# visualizacão da distribuição por violinplot\n",
    "sns.violinplot(data=df[(df.affairs > 0) & (df.affairs < 9)], x='age', y = 'affairs')\n",
    "plt.ylim(-2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=df[['affairs', 'age', 'yrs_married', 'children', 'religious']], \n",
    "        plot_kws = {'alpha':0.08, 's':180, 'edgecolor': None}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre-processamento\n",
    "\n",
    "Notamos as variaveis categoricas Occupation e Husband's Occupation. De maneira similar a regressão linear, precisamos tratar essas colunas. Nesse caso, fazemos um OHE (one hot encoding). Importante: Labelencoding não funciona!!\n",
    "\n",
    "Pandas tem um método para criar esses [dummy variables](http://en.wikipedia.org/wiki/Dummy_variable_%28statistics%29) criando colunas dedicadas para cada valor encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cria novo DataFrame para as colunas categoricas\n",
    "occ_dummies = pd.get_dummies(df['occupation'])\n",
    "hus_occ_dummies = pd.get_dummies(df['occupation_husb'])\n",
    "\n",
    "occ_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Atribui nomes as colunas\n",
    "occ_dummies.columns = ['occ1','occ2','occ3','occ4','occ5','occ6']\n",
    "hus_occ_dummies.columns = ['hocc1','hocc2','hocc3','hocc4','hocc5','hocc6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Atribui X primeiramente sem as colunas categoricas \n",
    "X = df.drop(['occupation','occupation_husb','teve_affair'],axis=1)\n",
    "\n",
    "# Concatena os dataframes dummies\n",
    "dummies = pd.concat([occ_dummies,hus_occ_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatena o X com o dataframe dos dummies\n",
    "X = pd.concat([X,dummies],axis=1)\n",
    "\n",
    "# amostragem do X\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multicolinearidade\n",
    "\n",
    "Notar que nos dataframe com as variaveis dummies, uma das colunas é combinação linear das outras.\n",
    "\n",
    "Por exemplo, o valor da primeira coluna será igual a $1 - \\sum_{i=2}^{k} x_i$, onde $x_i$ é o valor da coluna $i$ na mesma observação, e $k$ é a cardinalidade (quantidade de valores possíveis) da coluna categorica original.\n",
    "\n",
    "Para remediar esse problema, bem simples, basta deletar uma das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deletando uma coluna para cada coluna categorica\n",
    "X = X.drop('occ1',axis=1)\n",
    "X = X.drop('hocc1',axis=1)\n",
    "\n",
    "# deletando coluna não utilizada\n",
    "X = X.drop('affairs',axis=1)\n",
    "\n",
    "# amostragem\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alternativa\n",
    "Por razões didáticas o roteiro acima foi apresentado, mas todo ele pode ser resumido em apenas uma linha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = pd.get_dummies(df, columns=['occupation', 'occupation_husb'], \n",
    "#                    drop_first=True).drop(['affairs', 'teve_affair'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separando o vetor y \n",
    "Agora que já temos a matriz com as features definidas, vamos retirar a coluna resposta em um vetor a parte ($y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Atribui y a coluna teve_affair\n",
    "y = df.teve_affair\n",
    "\n",
    "# amostragem do y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transformando em numpy\n",
    "y = y.values\n",
    "\n",
    "# checando resultado\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[3683]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rodando Regressão Logistica com sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciando objeto\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "log_model.fit(X, y)\n",
    "\n",
    "# Checando acurácia\n",
    "log_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checando a percentagem de pessoas com casos extra-conjugais\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coeff_df = DataFrame(X.columns, np.transpose(list(log_model.coef_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_df = DataFrame(log_model.coef_)\n",
    "\n",
    "coeff_df.columns = X.columns\n",
    "\n",
    "coeff_df = coeff_df.T\n",
    "\n",
    "coeff_df.columns = ['coeficiente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_df.plot(kind='bar', figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O que podemos observar pelos coeficientes acima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Segmentando a base\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Instanciando um objeto\n",
    "log_model2 = LogisticRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "log_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predizendo a classe das observações de teste\n",
    "class_predict = log_model2.predict(X_test)\n",
    "\n",
    "# Comparando as classes da predição e o gold, \n",
    "# ou seja, medindo a performance...\n",
    "print (metrics.accuracy_score(y_test,class_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analise de resultados via matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matriz de confusão\n",
    "metrics.confusion_matrix(y_test, class_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Label gold na vertical, e label predição na horizontal\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, class_predict), annot=True, fmt ='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, class_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Quanto devemos acertar...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob. verdadeiro positivo: 0.09\n",
      "prob. verdadeiro negativo: 0.48999999999999994\n",
      "prob. falso positivo: 0.21\n",
      "prob. falso negativo: 0.21\n"
     ]
    }
   ],
   "source": [
    "# se não sabemos nada da pessoa, o melhor 'chute' seria jogar uma moeda com 30% de probabilidade de cara (label = 1)\n",
    "# 30% é a media do vetor y (arredondado)\n",
    "\n",
    "# nesse caso teriamos:\n",
    "print('prob. verdadeiro positivo:', 0.3 * 0.3)\n",
    "print('prob. verdadeiro negativo:', 0.7 * 0.7)\n",
    "print('prob. falso positivo:', 0.7 * 0.3)\n",
    "print('prob. falso negativo:', 0.3 * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia 0.58\n"
     ]
    }
   ],
   "source": [
    "print('acuracia', 0.3 * 0.3 + 0.7 * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob. verdadeiro positivo: 0.0\n",
      "prob. verdadeiro negativo: 0.7\n",
      "prob. falso positivo: 0.0\n",
      "prob. falso negativo: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Na realidade esse não é o melhor chute para maximizar a acuracia. \n",
    "# para maximizar a acuracia, o melhor chute seria 'chutar' tudo 0. \n",
    "# nesse caso teriamos:\n",
    "\n",
    "print('prob. verdadeiro positivo:', 0.3 * 0)\n",
    "print('prob. verdadeiro negativo:', 0.7 * 1)\n",
    "print('prob. falso positivo:', 0.7 * 0)\n",
    "print('prob. falso negativo:', 0.3 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia 0.7\n"
     ]
    }
   ],
   "source": [
    "print('acuracia', 0.3 * 0 + 0.7 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
